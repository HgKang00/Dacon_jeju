{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136132eb0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "from utils import data_split\n",
    "\n",
    "# 모든 경고 메시지를 무시하고 출력하지 않음\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Model\n",
    "import torch    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "from layers.Embed import DataEmbedding\n",
    "from layers.Conv_Blocks import Inception_Block_V1   \n",
    "            #convolution block used for convoluting the 2D time data, changeable\n",
    "\n",
    "## Train\n",
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "## seed\n",
    "seed_value = 36\n",
    "\n",
    "# PyTorch의 랜덤 시드 설정\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_code = ['BC_C_J', 'TG_B_J', 'CR_B_J', 'RD_E_S', 'BC_A_J', 'CB_F_J', 'RD_D_J', 'TG_A_S', 'BC_E_S', 'CR_D_J', 'BC_A_S', 'BC_B_S', 'TG_E_J', \n",
    "               'CR_E_S', 'RD_F_J', 'BC_E_J', 'TG_A_J', 'CR_C_J', 'CR_D_S', 'TG_C_J', 'CB_A_S', 'TG_D_J', 'CR_E_J', 'RD_C_S', 'BC_C_S', 'CB_E_J', \n",
    "               'RD_E_J', 'BC_D_J', 'CR_A_J', 'TG_E_S', 'TG_C_S', 'TG_D_S', 'RD_A_S', 'RD_A_J', 'RD_D_S', 'TG_B_S', 'CB_D_J', 'CB_A_J', 'BC_B_J']\n",
    "\n",
    "data = pd.read_csv('~/Developer/private/Dacon/jeju/data/train.csv')\n",
    "data_list = data_split(data)\n",
    "\n",
    "dataset = {}\n",
    "march_data = {}\n",
    "for code in unique_code:\n",
    "    march_data[code] = {}\n",
    "    march_data[code]['2019'] = data_list[f'data_{code}'][(data_list[f'data_{code}']['timestamp'] >= '2019-03-04') & (data_list[f'data_{code}']['timestamp'] <= '2019-03-31')].reset_index(drop = True)\n",
    "    march_data[code]['2020'] = data_list[f'data_{code}'][(data_list[f'data_{code}']['timestamp'] >= '2020-03-04') & (data_list[f'data_{code}']['timestamp'] <= '2020-03-31')].reset_index(drop = True)\n",
    "    march_data[code]['2021'] = data_list[f'data_{code}'][(data_list[f'data_{code}']['timestamp'] >= '2021-03-04') & (data_list[f'data_{code}']['timestamp'] <= '2021-03-31')].reset_index(drop = True)\n",
    "    march_data[code]['2022'] = data_list[f'data_{code}'][(data_list[f'data_{code}']['timestamp'] >= '2022-03-04') & (data_list[f'data_{code}']['timestamp'] <= '2022-03-31')].reset_index(drop = True)\n",
    "    \n",
    "\n",
    "    avg_supply = []\n",
    "    for i in range(28):\n",
    "        supply_19 = march_data[code]['2019']['supply(kg)'][i]\n",
    "        supply_20 = march_data[code]['2020']['supply(kg)'][i] \n",
    "        supply_21 = march_data[code]['2021']['supply(kg)'][i] \n",
    "        supply_22 =march_data[code]['2022']['supply(kg)'][i] \n",
    "\n",
    "        supplies = [supply_19, supply_20, supply_21, supply_22]\n",
    "        filtered_supplies = [supply for supply in supplies if supply != 0]\n",
    "\n",
    "        # 평균 계산\n",
    "        if filtered_supplies:\n",
    "            average_supply = sum(filtered_supplies) / len(filtered_supplies)\n",
    "        else: \n",
    "            average_supply = 0\n",
    "        \n",
    "        avg_supply.append(average_supply)\n",
    "\n",
    "    zero_sunday = [1, 8, 15, 22]\n",
    "    for idx in zero_sunday:\n",
    "        avg_supply[idx] = 0\n",
    "\n",
    "\n",
    "    avg_price = []\n",
    "    for i in range(28):\n",
    "        price_19 = march_data[code]['2019']['price(원/kg)'][i]\n",
    "        price_20 = march_data[code]['2020']['price(원/kg)'][i] \n",
    "        price_21 = march_data[code]['2021']['price(원/kg)'][i] \n",
    "        price_22 =march_data[code]['2022']['price(원/kg)'][i] \n",
    "\n",
    "        prices = [price_19, price_20, price_21, price_22]\n",
    "        filtered_prices = [price for price in prices if price != 0]\n",
    "\n",
    "        # 평균 계산\n",
    "        if filtered_prices:\n",
    "            average_price = sum(filtered_prices) / len(filtered_prices)\n",
    "        else: \n",
    "            average_price = 0\n",
    "        \n",
    "        avg_price.append(average_price)\n",
    "        \n",
    "\n",
    "    zero_sunday = [1, 8, 15, 22]\n",
    "    for idx in zero_sunday:\n",
    "        avg_price[idx] = 0\n",
    "\n",
    "\n",
    "    march_data[code]['avg_supply'] = avg_supply\n",
    "    march_data[code]['avg_price'] = avg_price\n",
    "\n",
    "    # 2023년 3월 test용 데이터셋 생성\n",
    "    new_df = march_data[code]['2019'].copy()\n",
    "    # 'ID'의 연도를 2023으로 변경\n",
    "    new_df['ID'] = new_df['ID'].apply(lambda x: f\"{x[:5]}2023{x[9:]}\")\n",
    "    # 'timestamp'의 연도를 2023으로 변경\n",
    "    new_df['timestamp'] = new_df['timestamp'].apply(lambda x: f\"2023-{x[5:]}\")\n",
    "    # supply와 price의 평균값으로 변경\n",
    "    new_df['supply(kg)'] = avg_supply\n",
    "    new_df['price(원/kg)'] = avg_price\n",
    "\n",
    "    march_data[code]['2023'] = new_df\n",
    "    \n",
    "\n",
    "    # 원래 데이터와 합침\n",
    "    merged_df = pd.concat([data_list[f'data_{code}'], march_data[code]['2023']], axis=0, ignore_index=True)\n",
    "    dataset[code] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 64\n",
    "label_len = 28\n",
    "pred_len = 28\n",
    "\n",
    "type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "flag = 'train'\n",
    "set_type = type_map[flag]\n",
    "features = 'S' # single or multi\n",
    "target = 'price(원/kg)' \n",
    "scale = True\n",
    "timeenc = 0 # time_feature가 존재하는지 여부 : 없으면 임의로 생성해주지만 우리 데이터에는 존재함\n",
    "freq = 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_jeju(Dataset):\n",
    "        def __init__(self, flag='train', size=[64,28,28],\n",
    "             features='S', scale=True, timeenc=0, freq='d', code = None, seasonal_patterns='Monthly'):\n",
    "            # size [seq_len, label_len, pred_len]\n",
    "            # info\n",
    "            if size == None:\n",
    "                self.seq_len = 24 * 4 * 4 # 16일 데이터를 이용해 \n",
    "                self.label_len = 24 * 4 \n",
    "                self.pred_len = 24 * 4 # 4일간의 데이터 예측? 28\n",
    "            else:\n",
    "                self.seq_len = size[0]\n",
    "                self.label_len = size[1]\n",
    "                self.pred_len = size[2]\n",
    "            # init\n",
    "            assert flag in ['train', 'test', 'val']\n",
    "            type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "            self.set_type = type_map[flag]\n",
    "            self.features = features\n",
    "            self.target = target\n",
    "            self.scale = scale\n",
    "            self.timeenc = timeenc\n",
    "            self.freq = freq\n",
    "            self.code = code\n",
    "\n",
    "            self.train_mean = None\n",
    "            self.train_std = None\n",
    "\n",
    "            # After initialization, call __read_data__() to manage the data file.\n",
    "            self.__read_data__()\n",
    "\n",
    "        def __read_data__(self):\n",
    "                self.scaler = StandardScaler()\n",
    "\n",
    "                #get raw data from path\n",
    "                # df_raw = data_list[f\"data_{self.code}\"]\n",
    "                df_raw = dataset[self.code]\n",
    "\n",
    "                # split data set into train, vali, test. border1 is the left border and border2 is the right.\n",
    "                # Once flag(train, vali, test) is determined, __read_data__ will return certain part of the dataset.\n",
    "                border1s = [0, 1400 - seq_len, 1523 - seq_len]\n",
    "                border2s = [1400, 1523, 1551]\n",
    "                border1 = border1s[self.set_type]\n",
    "                border2 = border2s[self.set_type]\n",
    "\n",
    "                #decide which columns to select\n",
    "                if self.features == 'M' or self.features == 'MS':\n",
    "                        cols_data = df_raw.columns[1:] # column name list (remove 'date')\n",
    "                        df_data = df_raw[cols_data]  #remove the first column, which is time stamp info\n",
    "                elif self.features == 'S':\n",
    "                        df_data = df_raw[[self.target]] # target column\n",
    "\n",
    "                #scale data by the scaler that fits training data\n",
    "                if self.scale:\n",
    "                        train_data = df_data[border1s[0]:border2s[0]]\n",
    "                        #train_data.values: turn pandas DataFrame into 2D numpy\n",
    "                        self.train_mean = train_data.mean().values\n",
    "                        self.train_std = train_data.std().values\n",
    "                        self.scaler.fit(train_data.values)  \n",
    "                        data = self.scaler.transform(df_data.values)\n",
    "                else:\n",
    "                        data = df_data.values \n",
    "                \n",
    "                # 날짜를 년/월/일/요일 형태로 자르고 리스트로 변환\n",
    "                # [[2019    1    1    1]\n",
    "                #  [2019    1    2    2]\n",
    "                #  [2019    1    3    3]\n",
    "                #  ...\n",
    "                \n",
    "                df_stamp = df_raw[['timestamp']][border1:border2]\n",
    "                df_stamp['timestamp'] = pd.to_datetime(df_stamp.timestamp) \n",
    "\n",
    "                if self.timeenc == 0:  #time feature encoding is fixed or learned\n",
    "                        # df_stamp['year'] = df_stamp.timestamp.apply(lambda row: row.year, 1)\n",
    "                        df_stamp['month'] = df_stamp.timestamp.apply(lambda row: row.month, 1)\n",
    "                        df_stamp['day'] = df_stamp.timestamp.apply(lambda row: row.day, 1)\n",
    "                        df_stamp['weekday'] = df_stamp.timestamp.apply(lambda row: row.weekday(), 1)\n",
    "                        \n",
    "                        #now df_frame has multiple columns recording the month, day etc. time stamp\n",
    "                        # next we delete the 'date' column and turn 'DataFrame' to a list\n",
    "                        data_stamp = df_stamp.drop(['timestamp'], axis = 1).values\n",
    "\n",
    "                # elif self.timeenc == 1: #time feature encoding is timeF\n",
    "                #         data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "                #         data_stamp = data_stamp.transpose(1, 0)\n",
    "                        \n",
    "                \n",
    "                # data_x and data_y are same copy of a certain part of data\n",
    "                self.data_x = data[border1:border2]\n",
    "                self.data_y = data[border1:border2]\n",
    "                self.data_stamp = data_stamp\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "                #given an index, calculate the positions after this index to truncate the dataset\n",
    "                s_begin = index\n",
    "                s_end = s_begin + self.seq_len\n",
    "                r_begin = s_end - self.label_len\n",
    "                r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "                #input and output sequence\n",
    "                seq_x = self.data_x[s_begin:s_end]\n",
    "                seq_y = self.data_y[r_begin:r_end]\n",
    "\n",
    "                #time mark\n",
    "                seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "                seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "                return seq_x, seq_y, seq_x_mark, seq_y_mark, self.train_mean, self.train_std\n",
    "\n",
    "        def __len__(self):\n",
    "                return len(self.data_x) - self.seq_len - self.pred_len + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='d'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "        year_size = 6\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "        # self.year_embed = Embed(year_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "        # year_x = self.year_embed(x[:, :, 0])\n",
    "\n",
    "        # return year_x + weekday_x + day_x + month_x \n",
    "        return weekday_x + day_x + month_x \n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def FFT_for_Period(x, k=5):\n",
    "    # [B, T, C]\n",
    "    xf = torch.fft.rfft(x, dim=1)\n",
    "    # find period by amplitudes\n",
    "    frequency_list = abs(xf).mean(0).mean(-1)\n",
    "    frequency_list[0] = 0\n",
    "    _, top_list = torch.topk(frequency_list, k)\n",
    "    top_list = top_list.detach().cpu().numpy()\n",
    "    period = x.shape[1] // top_list\n",
    "    return period, abs(xf).mean(-1)[:, top_list]\n",
    "\n",
    "\n",
    "class TimesBlock(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(TimesBlock, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.k = configs.top_k\n",
    "        # parameter-efficient design\n",
    "        self.conv = nn.Sequential(\n",
    "            Inception_Block_V1(configs.d_model, configs.d_ff,\n",
    "                               num_kernels=configs.num_kernels),\n",
    "            nn.GELU(),\n",
    "            Inception_Block_V1(configs.d_ff, configs.d_model,\n",
    "                               num_kernels=configs.num_kernels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, N = x.size()\n",
    "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
    "\n",
    "        res = []\n",
    "        for i in range(self.k):\n",
    "            period = period_list[i]\n",
    "            # padding\n",
    "            if (self.seq_len + self.pred_len) % period != 0:\n",
    "                length = (\n",
    "                                 ((self.seq_len + self.pred_len) // period) + 1) * period\n",
    "                padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n",
    "                out = torch.cat([x, padding], dim=1)\n",
    "            else:\n",
    "                length = (self.seq_len + self.pred_len)\n",
    "                out = x\n",
    "            # reshape\n",
    "            out = out.reshape(B, length // period, period,\n",
    "                              N).permute(0, 3, 1, 2).contiguous()\n",
    "            # 2D conv: from 1d Variation to 2d Variation\n",
    "            out = self.conv(out)\n",
    "            # reshape back\n",
    "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
    "            res.append(out[:, :(self.seq_len + self.pred_len), :])\n",
    "        res = torch.stack(res, dim=-1)\n",
    "        # adaptive aggregation\n",
    "        period_weight = F.softmax(period_weight, dim=1)\n",
    "        period_weight = period_weight.unsqueeze(\n",
    "            1).unsqueeze(1).repeat(1, T, N, 1)\n",
    "        res = torch.sum(res * period_weight, -1)\n",
    "        # residual connection\n",
    "        res = res + x\n",
    "        return res\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.model = nn.ModuleList([TimesBlock(configs)\n",
    "                                    for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            self.predict_linear = nn.Linear(\n",
    "                self.seq_len, self.pred_len + self.seq_len)\n",
    "            self.projection = nn.Linear(\n",
    "                configs.d_model, configs.c_out, bias=True)\n",
    "\n",
    "\n",
    "    def forecast(self, x_enc, x_mark_enc):\n",
    "        # Normalization from Non-stationary Transformer\n",
    "        means = x_enc.mean(1, keepdim=True).detach()\n",
    "        x_enc = x_enc - means\n",
    "        stdev = torch.sqrt(\n",
    "            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "        x_enc /= stdev\n",
    "\n",
    "        # embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C]\n",
    "        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n",
    "            0, 2, 1)  # align temporal dimension\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # porject back\n",
    "        dec_out = self.projection(enc_out)\n",
    "\n",
    "        # De-Normalization from Non-stationary Transformer\n",
    "        dec_out = dec_out * \\\n",
    "                  (stdev[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        dec_out = dec_out + \\\n",
    "                  (means[:, 0, :].unsqueeze(1).repeat(\n",
    "                      1, self.pred_len + self.seq_len, 1))\n",
    "        return dec_out\n",
    "\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc):\n",
    "        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n",
    "            dec_out = self.forecast(x_enc, x_mark_enc)\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early_Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience # how many times will you tolerate for loss not being on decrease\n",
    "        self.verbose = verbose  # whether to print tip info\n",
    "        self.counter = 0 # now how many times loss not on decrease\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "\n",
    "        # meaning: current score is not 'delta' better than best_score, representing that \n",
    "        # further training may not bring remarkable improvement in loss. \n",
    "        elif score < self.best_score + self.delta:  \n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            # 'No Improvement' times become higher than patience --> Stop Further Training\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else: #model's loss is still on decrease, save the now best model and go on training\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "    ### used for saving the current best model\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.seq_len = 64\n",
    "        self.label_len = 28\n",
    "        self.pred_len = 28\n",
    "        self.top_k = 5\n",
    "        self.d_model = 32\n",
    "        self.d_ff = 32\n",
    "        self.num_kernels = 3\n",
    "        self.e_layers = 3\n",
    "        self.d_layers = 1\n",
    "        self.enc_in = 1\n",
    "        self.dec_in = 1\n",
    "        self.c_out = 1\n",
    "        self.embed = 16\n",
    "        self.freq = 'd'\n",
    "        self.dropout = 0.1\n",
    "        self.task_name = 'short_term_forecast'\n",
    "        self.c_out = 1\n",
    "        self.seasonal_patternes = 'Monthly'\n",
    "        self.features = 'S'\n",
    "\n",
    "configs = Configs()\n",
    "\n",
    "seq_len = 64\n",
    "label_len = 28\n",
    "pred_len = 28\n",
    "\n",
    "type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "flag = 'train'\n",
    "set_type = type_map[flag]\n",
    "features = 'S' # single or multi\n",
    "target = 'price(원/kg)' \n",
    "scale = True\n",
    "timeenc = 0 # time_feature가 존재하는지 여부 : 없으면 임의로 생성해주지만 우리 데이터에는 존재함\n",
    "freq = 'd'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali(model, vali_loader, criterion):\n",
    "        total_loss = []\n",
    "\n",
    "        #evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark,_,_) in enumerate(vali_loader):\n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float()\n",
    "\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "                \n",
    "                outputs = model(batch_x, batch_x_mark)\n",
    "                f_dim = 0\n",
    "                outputs = outputs[:, -pred_len:, f_dim:]\n",
    "                batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_y.detach().cpu()\n",
    "\n",
    "                loss = criterion(pred, true)\n",
    "\n",
    "                total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        model.train()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--training for BC_C_J\n",
      "tensor(865.9229, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 10.36693811416626\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6586257 Vali Loss: 0.5644054 Test Loss: 0.3126791\n",
      "Validation loss decreased (inf --> 0.564405).  Saving model ...\n",
      "Epoch: 2 cost time: 8.745888948440552\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4342750 Vali Loss: 0.5139981 Test Loss: 0.7203006\n",
      "Validation loss decreased (0.564405 --> 0.513998).  Saving model ...\n",
      "Epoch: 3 cost time: 9.652954339981079\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3815873 Vali Loss: 0.5409241 Test Loss: 0.3475225\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.410433769226074\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3561093 Vali Loss: 0.5289378 Test Loss: 0.4211972\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.28098201751709\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3306037 Vali Loss: 0.5539362 Test Loss: 0.1891588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_B_J\n",
      "tensor(3462.3943, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.421173095703125\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6677467 Vali Loss: 0.0804180 Test Loss: 0.1550239\n",
      "Validation loss decreased (inf --> 0.080418).  Saving model ...\n",
      "Epoch: 2 cost time: 8.83382511138916\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4302136 Vali Loss: 0.0631892 Test Loss: 0.1279876\n",
      "Validation loss decreased (0.080418 --> 0.063189).  Saving model ...\n",
      "Epoch: 3 cost time: 8.53545093536377\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3888155 Vali Loss: 0.0602345 Test Loss: 0.0960122\n",
      "Validation loss decreased (0.063189 --> 0.060235).  Saving model ...\n",
      "Epoch: 4 cost time: 8.608339786529541\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3663514 Vali Loss: 0.0639282 Test Loss: 0.0962599\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.757224082946777\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3351623 Vali Loss: 0.0792243 Test Loss: 0.0855078\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.527766942977905\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3054808 Vali Loss: 0.0623386 Test Loss: 0.0784421\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_B_J\n",
      "tensor(143.4264, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.642992973327637\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8173791 Vali Loss: 6.2888112 Test Loss: 1.6129946\n",
      "Validation loss decreased (inf --> 6.288811).  Saving model ...\n",
      "Epoch: 2 cost time: 9.231031656265259\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.6859680 Vali Loss: 6.3594794 Test Loss: 1.5232290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.66271710395813\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.6135130 Vali Loss: 6.2702241 Test Loss: 1.8657811\n",
      "Validation loss decreased (6.288811 --> 6.270224).  Saving model ...\n",
      "Epoch: 4 cost time: 8.709017038345337\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.5165571 Vali Loss: 6.3045411 Test Loss: 1.9771985\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.852546691894531\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4249346 Vali Loss: 6.8123946 Test Loss: 2.0690267\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 9.344969034194946\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3314352 Vali Loss: 7.1263747 Test Loss: 2.4049532\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_E_S\n",
      "tensor(108.8536, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.731280088424683\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7711300 Vali Loss: 1.5344658 Test Loss: 0.8278130\n",
      "Validation loss decreased (inf --> 1.534466).  Saving model ...\n",
      "Epoch: 2 cost time: 8.359983921051025\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5603653 Vali Loss: 1.6542503 Test Loss: 0.8558527\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.451298952102661\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.5037601 Vali Loss: 1.5322480 Test Loss: 1.1316880\n",
      "Validation loss decreased (1.534466 --> 1.532248).  Saving model ...\n",
      "Epoch: 4 cost time: 8.618010759353638\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4646185 Vali Loss: 1.6579529 Test Loss: 0.9129363\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.356202125549316\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4373117 Vali Loss: 1.6026644 Test Loss: 0.8739461\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.775207996368408\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4047636 Vali Loss: 1.6295105 Test Loss: 0.7305427\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_A_J\n",
      "tensor(1348.7507, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.47608995437622\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6886858 Vali Loss: 0.4362818 Test Loss: 0.2425293\n",
      "Validation loss decreased (inf --> 0.436282).  Saving model ...\n",
      "Epoch: 2 cost time: 8.747558832168579\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4468570 Vali Loss: 0.4573182 Test Loss: 0.2569882\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.868927955627441\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3926166 Vali Loss: 0.5204381 Test Loss: 0.1085470\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 8.942599058151245\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3662568 Vali Loss: 0.5345719 Test Loss: 0.2161704\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CB_F_J\n",
      "tensor(253.1821, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.403165817260742\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.5581257 Vali Loss: 0.4617852 Test Loss: 0.1653676\n",
      "Validation loss decreased (inf --> 0.461785).  Saving model ...\n",
      "Epoch: 2 cost time: 8.535851955413818\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3097588 Vali Loss: 0.4126523 Test Loss: 0.1359758\n",
      "Validation loss decreased (0.461785 --> 0.412652).  Saving model ...\n",
      "Epoch: 3 cost time: 8.525767803192139\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2646595 Vali Loss: 0.4453322 Test Loss: 0.1015833\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.513384103775024\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2338018 Vali Loss: 0.4114681 Test Loss: 0.0927824\n",
      "Validation loss decreased (0.412652 --> 0.411468).  Saving model ...\n",
      "Epoch: 5 cost time: 8.740381956100464\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2133358 Vali Loss: 0.4442497 Test Loss: 0.1006386\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 8.524755954742432\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2003662 Vali Loss: 0.4354881 Test Loss: 0.0668237\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 8.527805805206299\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.1854173 Vali Loss: 0.3696087 Test Loss: 0.1079540\n",
      "Validation loss decreased (0.411468 --> 0.369609).  Saving model ...\n",
      "Epoch: 8 cost time: 8.547450065612793\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.1731242 Vali Loss: 0.5183298 Test Loss: 0.1609441\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 9 cost time: 8.372005224227905\n",
      "Epoch: 9, Steps: 81 | Train Loss: 0.1573611 Vali Loss: 0.4270762 Test Loss: 0.1131989\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 10 cost time: 8.527048826217651\n",
      "Epoch: 10, Steps: 81 | Train Loss: 0.1523140 Vali Loss: 0.4588148 Test Loss: 0.1161999\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_D_J\n",
      "tensor(173.7707, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.253396987915039\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7252395 Vali Loss: 0.5964906 Test Loss: 1.0478561\n",
      "Validation loss decreased (inf --> 0.596491).  Saving model ...\n",
      "Epoch: 2 cost time: 8.330078840255737\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4871993 Vali Loss: 0.6181678 Test Loss: 1.3701752\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.363627910614014\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4288759 Vali Loss: 0.5414118 Test Loss: 1.2890532\n",
      "Validation loss decreased (0.596491 --> 0.541412).  Saving model ...\n",
      "Epoch: 4 cost time: 8.486389875411987\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3962637 Vali Loss: 0.6283178 Test Loss: 1.0737422\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.406439065933228\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3785113 Vali Loss: 0.5970449 Test Loss: 1.2154173\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.266451120376587\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3515445 Vali Loss: 0.6443512 Test Loss: 1.1428818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_A_S\n",
      "tensor(3798.0329, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.735046148300171\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.3608914 Vali Loss: 0.0551995 Test Loss: 0.0351216\n",
      "Validation loss decreased (inf --> 0.055199).  Saving model ...\n",
      "Epoch: 2 cost time: 8.740641117095947\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.1627043 Vali Loss: 0.0507195 Test Loss: 0.0238549\n",
      "Validation loss decreased (0.055199 --> 0.050719).  Saving model ...\n",
      "Epoch: 3 cost time: 8.777719020843506\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.1539371 Vali Loss: 0.0558925 Test Loss: 0.0386182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.694438934326172\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.1476043 Vali Loss: 0.0540946 Test Loss: 0.0320762\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.856979846954346\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.1419502 Vali Loss: 0.0667612 Test Loss: 0.0160540\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_E_S\n",
      "tensor(1029.1007, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.310322999954224\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6876688 Vali Loss: 0.6017982 Test Loss: 0.1226352\n",
      "Validation loss decreased (inf --> 0.601798).  Saving model ...\n",
      "Epoch: 2 cost time: 8.44746994972229\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4696731 Vali Loss: 0.5212402 Test Loss: 0.2057656\n",
      "Validation loss decreased (0.601798 --> 0.521240).  Saving model ...\n",
      "Epoch: 3 cost time: 8.618385791778564\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4225549 Vali Loss: 0.5812682 Test Loss: 0.3832062\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.76449203491211\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3961005 Vali Loss: 0.6244439 Test Loss: 0.5812994\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.567395210266113\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3799019 Vali Loss: 0.6145279 Test Loss: 0.5749648\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_D_J\n",
      "tensor(363.8564, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.668982028961182\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6500232 Vali Loss: 2.9966033 Test Loss: 3.0250020\n",
      "Validation loss decreased (inf --> 2.996603).  Saving model ...\n",
      "Epoch: 2 cost time: 8.73894214630127\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3829632 Vali Loss: 2.5658686 Test Loss: 3.5192697\n",
      "Validation loss decreased (2.996603 --> 2.565869).  Saving model ...\n",
      "Epoch: 3 cost time: 8.898771047592163\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3253662 Vali Loss: 2.4687860 Test Loss: 3.7611916\n",
      "Validation loss decreased (2.565869 --> 2.468786).  Saving model ...\n",
      "Epoch: 4 cost time: 8.798789262771606\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2835226 Vali Loss: 2.4974787 Test Loss: 3.1744335\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.819279193878174\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2733759 Vali Loss: 2.4880078 Test Loss: 3.4336226\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.759297847747803\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2645882 Vali Loss: 2.3754559 Test Loss: 4.4690561\n",
      "Validation loss decreased (2.468786 --> 2.375456).  Saving model ...\n",
      "Epoch: 7 cost time: 8.751697301864624\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2524802 Vali Loss: 2.4150925 Test Loss: 4.9373236\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 8 cost time: 8.710386037826538\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.2403205 Vali Loss: 2.5973473 Test Loss: 2.9799173\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 9 cost time: 8.714186191558838\n",
      "Epoch: 9, Steps: 81 | Train Loss: 0.2227406 Vali Loss: 2.5227416 Test Loss: 4.6927495\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_A_S\n",
      "tensor(1169.3843, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.18438720703125\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7514492 Vali Loss: 0.4070294 Test Loss: 0.2252309\n",
      "Validation loss decreased (inf --> 0.407029).  Saving model ...\n",
      "Epoch: 2 cost time: 8.308633804321289\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5081333 Vali Loss: 0.4073831 Test Loss: 0.0749040\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.43584418296814\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4522872 Vali Loss: 0.5550703 Test Loss: 0.0533242\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 8.646436929702759\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4100777 Vali Loss: 0.5335323 Test Loss: 0.0673858\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_B_S\n",
      "tensor(80.6314, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.339515924453735\n",
      "Epoch: 1, Steps: 81 | Train Loss: 1.0186928 Vali Loss: 0.2786919 Test Loss: 17.3958607\n",
      "Validation loss decreased (inf --> 0.278692).  Saving model ...\n",
      "Epoch: 2 cost time: 8.40578293800354\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.8651090 Vali Loss: 0.2786186 Test Loss: 16.9069500\n",
      "Validation loss decreased (0.278692 --> 0.278619).  Saving model ...\n",
      "Epoch: 3 cost time: 8.11085295677185\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.8057479 Vali Loss: 0.2785880 Test Loss: 14.8121939\n",
      "Validation loss decreased (0.278619 --> 0.278588).  Saving model ...\n",
      "Epoch: 4 cost time: 8.210339069366455\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.6988752 Vali Loss: 0.2787288 Test Loss: 18.2741680\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.486746788024902\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.6167573 Vali Loss: 0.2785454 Test Loss: 17.2069569\n",
      "Validation loss decreased (0.278588 --> 0.278545).  Saving model ...\n",
      "Epoch: 6 cost time: 8.389890193939209\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.5397208 Vali Loss: 0.2785771 Test Loss: 17.5443611\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 7 cost time: 8.265918970108032\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.4595325 Vali Loss: 0.2785660 Test Loss: 20.3134155\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 8 cost time: 8.35401725769043\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.4100592 Vali Loss: 0.2785979 Test Loss: 17.9162960\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_E_J\n",
      "tensor(2284.9936, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.534149885177612\n",
      "Epoch: 1, Steps: 81 | Train Loss: 1.0102021 Vali Loss: 0.1305299 Test Loss: 0.7310635\n",
      "Validation loss decreased (inf --> 0.130530).  Saving model ...\n",
      "Epoch: 2 cost time: 8.274883031845093\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.7916290 Vali Loss: 0.0929603 Test Loss: 0.5467445\n",
      "Validation loss decreased (0.130530 --> 0.092960).  Saving model ...\n",
      "Epoch: 3 cost time: 8.445702075958252\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.7457130 Vali Loss: 0.1093697 Test Loss: 0.5911625\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.512451887130737\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.6892583 Vali Loss: 0.1034277 Test Loss: 0.4878487\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.351046085357666\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.6191450 Vali Loss: 0.1184385 Test Loss: 0.5004465\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_E_S\n",
      "tensor(20.1864, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.30644702911377\n",
      "Epoch: 1, Steps: 81 | Train Loss: 1.0083713 Vali Loss: 0.0000013 Test Loss: 0.9358501\n",
      "Validation loss decreased (inf --> 0.000001).  Saving model ...\n",
      "Epoch: 2 cost time: 8.492750883102417\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.8629348 Vali Loss: 0.0000010 Test Loss: 0.9360275\n",
      "Validation loss decreased (0.000001 --> 0.000001).  Saving model ...\n",
      "Epoch: 3 cost time: 8.386751890182495\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.8291682 Vali Loss: 0.0000010 Test Loss: 0.9360765\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.412631750106812\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.7562933 Vali Loss: 0.0000011 Test Loss: 0.9360800\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.363078117370605\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.7222167 Vali Loss: 0.0000013 Test Loss: 0.9360673\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_F_J\n",
      "tensor(249.9157, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.217183828353882\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8444630 Vali Loss: 0.9154405 Test Loss: 0.1037822\n",
      "Validation loss decreased (inf --> 0.915440).  Saving model ...\n",
      "Epoch: 2 cost time: 8.138582944869995\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5364856 Vali Loss: 0.7675855 Test Loss: 0.0573176\n",
      "Validation loss decreased (0.915440 --> 0.767585).  Saving model ...\n",
      "Epoch: 3 cost time: 8.329375982284546\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4506466 Vali Loss: 0.7059247 Test Loss: 0.1350826\n",
      "Validation loss decreased (0.767585 --> 0.705925).  Saving model ...\n",
      "Epoch: 4 cost time: 8.223016023635864\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4236721 Vali Loss: 0.6973409 Test Loss: 0.1035314\n",
      "Validation loss decreased (0.705925 --> 0.697341).  Saving model ...\n",
      "Epoch: 5 cost time: 8.199980020523071\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4140517 Vali Loss: 0.7853101 Test Loss: 0.3099384\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 8.293337106704712\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4192091 Vali Loss: 0.6630104 Test Loss: 0.1439780\n",
      "Validation loss decreased (0.697341 --> 0.663010).  Saving model ...\n",
      "Epoch: 7 cost time: 8.247089147567749\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.3900838 Vali Loss: 0.7399051 Test Loss: 0.1425873\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 8 cost time: 8.520169019699097\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.3859868 Vali Loss: 0.7082372 Test Loss: 0.1170466\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 9 cost time: 8.336583852767944\n",
      "Epoch: 9, Steps: 81 | Train Loss: 0.3669600 Vali Loss: 0.6399582 Test Loss: 0.1056320\n",
      "Validation loss decreased (0.663010 --> 0.639958).  Saving model ...\n",
      "Epoch: 10 cost time: 8.364077091217041\n",
      "Epoch: 10, Steps: 81 | Train Loss: 0.3473043 Vali Loss: 0.7574465 Test Loss: 0.1211428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_E_J\n",
      "tensor(1291.7900, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.825462102890015\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6710581 Vali Loss: 0.4542682 Test Loss: 0.1459303\n",
      "Validation loss decreased (inf --> 0.454268).  Saving model ...\n",
      "Epoch: 2 cost time: 8.931252002716064\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4551203 Vali Loss: 0.3483118 Test Loss: 0.0831541\n",
      "Validation loss decreased (0.454268 --> 0.348312).  Saving model ...\n",
      "Epoch: 3 cost time: 8.701709032058716\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4033516 Vali Loss: 0.2732977 Test Loss: 0.0422496\n",
      "Validation loss decreased (0.348312 --> 0.273298).  Saving model ...\n",
      "Epoch: 4 cost time: 8.680148124694824\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3824135 Vali Loss: 0.3320610 Test Loss: 0.0380197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.731728076934814\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3776573 Vali Loss: 0.3958619 Test Loss: 0.0984813\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.976660013198853\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3548031 Vali Loss: 0.2986859 Test Loss: 0.3594322\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_A_J\n",
      "tensor(2656.7971, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.881829977035522\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8080758 Vali Loss: 0.0744423 Test Loss: 0.3375860\n",
      "Validation loss decreased (inf --> 0.074442).  Saving model ...\n",
      "Epoch: 2 cost time: 8.449151992797852\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5985401 Vali Loss: 0.0481003 Test Loss: 0.1555165\n",
      "Validation loss decreased (0.074442 --> 0.048100).  Saving model ...\n",
      "Epoch: 3 cost time: 8.582648038864136\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.5403353 Vali Loss: 0.0556133 Test Loss: 0.1280043\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.812816858291626\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.5144250 Vali Loss: 0.0554678 Test Loss: 0.1152773\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.82263970375061\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4758183 Vali Loss: 0.0535331 Test Loss: 0.1443584\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_C_J\n",
      "tensor(251.9936, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.41183590888977\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8059537 Vali Loss: 3.0201399 Test Loss: 1.5854361\n",
      "Validation loss decreased (inf --> 3.020140).  Saving model ...\n",
      "Epoch: 2 cost time: 8.681993007659912\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.6256033 Vali Loss: 2.6879909 Test Loss: 2.4006298\n",
      "Validation loss decreased (3.020140 --> 2.687991).  Saving model ...\n",
      "Epoch: 3 cost time: 8.923452854156494\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.5527085 Vali Loss: 2.6404984 Test Loss: 3.6087508\n",
      "Validation loss decreased (2.687991 --> 2.640498).  Saving model ...\n",
      "Epoch: 4 cost time: 8.796239852905273\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4984413 Vali Loss: 2.8313019 Test Loss: 3.2154574\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.445559740066528\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4336214 Vali Loss: 2.8534956 Test Loss: 3.8485849\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.440293788909912\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3778151 Vali Loss: 2.7539749 Test Loss: 5.2365227\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_D_S\n",
      "tensor(4.6786, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.295405149459839\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.4443073 Vali Loss: 12.4922800 Test Loss: 2.7392709\n",
      "Validation loss decreased (inf --> 12.492280).  Saving model ...\n",
      "Epoch: 2 cost time: 8.363091945648193\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4222612 Vali Loss: 12.4965143 Test Loss: 2.7391312\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.33177399635315\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4082616 Vali Loss: 12.4816437 Test Loss: 2.7392943\n",
      "Validation loss decreased (12.492280 --> 12.481644).  Saving model ...\n",
      "Epoch: 4 cost time: 8.547582149505615\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4197610 Vali Loss: 12.4981728 Test Loss: 2.7391384\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.23104214668274\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3904962 Vali Loss: 12.4872665 Test Loss: 2.7391887\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.477902173995972\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4154399 Vali Loss: 12.4914732 Test Loss: 2.7392693\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_C_J\n",
      "tensor(4280.0950, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.681002616882324\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6331322 Vali Loss: 0.0970149 Test Loss: 0.0563063\n",
      "Validation loss decreased (inf --> 0.097015).  Saving model ...\n",
      "Epoch: 2 cost time: 8.947911024093628\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3838549 Vali Loss: 0.0622734 Test Loss: 0.0362674\n",
      "Validation loss decreased (0.097015 --> 0.062273).  Saving model ...\n",
      "Epoch: 3 cost time: 8.870937824249268\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3546707 Vali Loss: 0.0571338 Test Loss: 0.0727091\n",
      "Validation loss decreased (0.062273 --> 0.057134).  Saving model ...\n",
      "Epoch: 4 cost time: 8.77813982963562\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3258488 Vali Loss: 0.0513935 Test Loss: 0.0768646\n",
      "Validation loss decreased (0.057134 --> 0.051393).  Saving model ...\n",
      "Epoch: 5 cost time: 8.79020094871521\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3035255 Vali Loss: 0.0539649 Test Loss: 0.0816290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 9.05307412147522\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2695280 Vali Loss: 0.0517589 Test Loss: 0.0577569\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 9.120760917663574\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2279641 Vali Loss: 0.0637343 Test Loss: 0.0656097\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CB_A_S\n",
      "tensor(10.8071, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.493899822235107\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.3701199 Vali Loss: 0.2696565 Test Loss: 20.7341728\n",
      "Validation loss decreased (inf --> 0.269657).  Saving model ...\n",
      "Epoch: 2 cost time: 8.425934076309204\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3124425 Vali Loss: 0.2696268 Test Loss: 16.4989014\n",
      "Validation loss decreased (0.269657 --> 0.269627).  Saving model ...\n",
      "Epoch: 3 cost time: 8.911518096923828\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2745941 Vali Loss: 0.2696488 Test Loss: 16.9937954\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 9.008384704589844\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2722913 Vali Loss: 0.2696488 Test Loss: 15.7718401\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 9.47019910812378\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2578586 Vali Loss: 0.2696370 Test Loss: 15.1373148\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_D_J\n",
      "tensor(2938.3186, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.679100036621094\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7563542 Vali Loss: 0.2593710 Test Loss: 0.8437498\n",
      "Validation loss decreased (inf --> 0.259371).  Saving model ...\n",
      "Epoch: 2 cost time: 8.855895757675171\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5093722 Vali Loss: 0.2598566 Test Loss: 0.5928068\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 9.154297113418579\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4546764 Vali Loss: 0.2741876 Test Loss: 0.3716397\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 9.378779888153076\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4257764 Vali Loss: 0.2705703 Test Loss: 0.3126952\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_E_J\n",
      "tensor(333.0336, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.599799156188965\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6850373 Vali Loss: 2.9337332 Test Loss: 3.0212648\n",
      "Validation loss decreased (inf --> 2.933733).  Saving model ...\n",
      "Epoch: 2 cost time: 9.06081509590149\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3851457 Vali Loss: 2.6349688 Test Loss: 5.9013820\n",
      "Validation loss decreased (2.933733 --> 2.634969).  Saving model ...\n",
      "Epoch: 3 cost time: 8.939435720443726\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3148297 Vali Loss: 2.6179068 Test Loss: 3.9360764\n",
      "Validation loss decreased (2.634969 --> 2.617907).  Saving model ...\n",
      "Epoch: 4 cost time: 8.93035626411438\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2999912 Vali Loss: 2.5423443 Test Loss: 3.4811280\n",
      "Validation loss decreased (2.617907 --> 2.542344).  Saving model ...\n",
      "Epoch: 5 cost time: 9.272341966629028\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2798220 Vali Loss: 2.5564945 Test Loss: 6.1805658\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 9.384852886199951\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2642837 Vali Loss: 2.4237707 Test Loss: 4.7642941\n",
      "Validation loss decreased (2.542344 --> 2.423771).  Saving model ...\n",
      "Epoch: 7 cost time: 9.221610069274902\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2473553 Vali Loss: 2.4334717 Test Loss: 5.7778020\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 8 cost time: 9.230348110198975\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.2374186 Vali Loss: 2.4773099 Test Loss: 5.7602878\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 9 cost time: 9.058000087738037\n",
      "Epoch: 9, Steps: 81 | Train Loss: 0.2286299 Vali Loss: 2.3724792 Test Loss: 5.2903800\n",
      "Validation loss decreased (2.423771 --> 2.372479).  Saving model ...\n",
      "Epoch: 10 cost time: 9.205897808074951\n",
      "Epoch: 10, Steps: 81 | Train Loss: 0.2091861 Vali Loss: 2.4025915 Test Loss: 6.3588381\n",
      "EarlyStopping counter: 1 out of 3\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_C_S\n",
      "tensor(4.7693, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 9.456760883331299\n",
      "Epoch: 1, Steps: 81 | Train Loss: 1.1466100 Vali Loss: 6.4812393 Test Loss: 10.8193369\n",
      "Validation loss decreased (inf --> 6.481239).  Saving model ...\n",
      "Epoch: 2 cost time: 9.552258014678955\n",
      "Epoch: 2, Steps: 81 | Train Loss: 1.0196270 Vali Loss: 6.4322467 Test Loss: 9.0931034\n",
      "Validation loss decreased (6.481239 --> 6.432247).  Saving model ...\n",
      "Epoch: 3 cost time: 9.574690818786621\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.9799605 Vali Loss: 6.4588323 Test Loss: 8.7491627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 9.84938383102417\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.8700656 Vali Loss: 6.4910064 Test Loss: 9.7293930\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 9.62745714187622\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.7679625 Vali Loss: 6.4870205 Test Loss: 9.1775723\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_C_S\n",
      "tensor(38.8507, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.39026403427124\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.9544920 Vali Loss: 1.1057897 Test Loss: 9.7644577\n",
      "Validation loss decreased (inf --> 1.105790).  Saving model ...\n",
      "Epoch: 2 cost time: 8.550987005233765\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.8691509 Vali Loss: 1.2219278 Test Loss: 10.0703554\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.646837949752808\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.8066727 Vali Loss: 1.1612756 Test Loss: 9.8610992\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 8.740587949752808\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.7426186 Vali Loss: 1.1787885 Test Loss: 10.1222992\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CB_E_J\n",
      "tensor(188.0736, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 9.288097143173218\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7977798 Vali Loss: 1.0466512 Test Loss: 1.5227377\n",
      "Validation loss decreased (inf --> 1.046651).  Saving model ...\n",
      "Epoch: 2 cost time: 9.431210041046143\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5373524 Vali Loss: 1.0638981 Test Loss: 1.9140922\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 9.51837682723999\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4530886 Vali Loss: 0.9873639 Test Loss: 2.4514015\n",
      "Validation loss decreased (1.046651 --> 0.987364).  Saving model ...\n",
      "Epoch: 4 cost time: 9.546014308929443\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3925248 Vali Loss: 1.0311222 Test Loss: 1.8268080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 9.573974132537842\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3656350 Vali Loss: 1.0301973 Test Loss: 2.2986257\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 9.298037052154541\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3151474 Vali Loss: 1.1323644 Test Loss: 2.0239186\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_E_J\n",
      "tensor(164.1579, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.906008958816528\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7549073 Vali Loss: 1.2528747 Test Loss: 0.1705614\n",
      "Validation loss decreased (inf --> 1.252875).  Saving model ...\n",
      "Epoch: 2 cost time: 9.221086978912354\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5241145 Vali Loss: 1.2350260 Test Loss: 0.2180029\n",
      "Validation loss decreased (1.252875 --> 1.235026).  Saving model ...\n",
      "Epoch: 3 cost time: 9.260669946670532\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4677870 Vali Loss: 1.1779758 Test Loss: 0.3787115\n",
      "Validation loss decreased (1.235026 --> 1.177976).  Saving model ...\n",
      "Epoch: 4 cost time: 9.424994945526123\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4384518 Vali Loss: 1.1535585 Test Loss: 0.1566421\n",
      "Validation loss decreased (1.177976 --> 1.153558).  Saving model ...\n",
      "Epoch: 5 cost time: 9.214354276657104\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4029767 Vali Loss: 1.2269529 Test Loss: 0.4271444\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 9.418654918670654\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3657135 Vali Loss: 1.2446276 Test Loss: 0.4111097\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 9.223820209503174\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.3206896 Vali Loss: 1.2697663 Test Loss: 0.4622410\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_D_J\n",
      "tensor(1134.7207, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 9.220675230026245\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.6533198 Vali Loss: 0.3949038 Test Loss: 0.1091025\n",
      "Validation loss decreased (inf --> 0.394904).  Saving model ...\n",
      "Epoch: 2 cost time: 10.950437784194946\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3805807 Vali Loss: 0.3426372 Test Loss: 0.1439011\n",
      "Validation loss decreased (0.394904 --> 0.342637).  Saving model ...\n",
      "Epoch: 3 cost time: 12.974536180496216\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3439100 Vali Loss: 0.3560918 Test Loss: 0.1401298\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 9.186239242553711\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2997200 Vali Loss: 0.3257650 Test Loss: 0.2895173\n",
      "Validation loss decreased (0.342637 --> 0.325765).  Saving model ...\n",
      "Epoch: 5 cost time: 9.148185014724731\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2849871 Vali Loss: 0.3563650 Test Loss: 0.1667876\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 9.24445915222168\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2710082 Vali Loss: 0.3659652 Test Loss: 0.3864675\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 9.50609278678894\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2549672 Vali Loss: 0.3327135 Test Loss: 0.3240655\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CR_A_J\n",
      "tensor(512.4271, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.639121055603027\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.4109897 Vali Loss: 1.7058984 Test Loss: 1.6102526\n",
      "Validation loss decreased (inf --> 1.705898).  Saving model ...\n",
      "Epoch: 2 cost time: 8.54784607887268\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.2644656 Vali Loss: 2.3370440 Test Loss: 1.8566369\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.861551761627197\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2294764 Vali Loss: 3.7765732 Test Loss: 2.3300231\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 8.639265060424805\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2031783 Vali Loss: 3.6931007 Test Loss: 1.6731532\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_E_S\n",
      "tensor(3191.4886, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.976087093353271\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.5933651 Vali Loss: 0.0763367 Test Loss: 0.0675345\n",
      "Validation loss decreased (inf --> 0.076337).  Saving model ...\n",
      "Epoch: 2 cost time: 9.360955953598022\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3803135 Vali Loss: 0.0744417 Test Loss: 0.0425955\n",
      "Validation loss decreased (0.076337 --> 0.074442).  Saving model ...\n",
      "Epoch: 3 cost time: 9.177189111709595\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3512833 Vali Loss: 0.0777491 Test Loss: 0.0522660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 9.25898289680481\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3285364 Vali Loss: 0.0736616 Test Loss: 0.0780143\n",
      "Validation loss decreased (0.074442 --> 0.073662).  Saving model ...\n",
      "Epoch: 5 cost time: 9.123037099838257\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2971796 Vali Loss: 0.0780447 Test Loss: 0.0621728\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 9.083912134170532\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2665637 Vali Loss: 0.0787252 Test Loss: 0.0454092\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 9.052703142166138\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2333641 Vali Loss: 0.0739566 Test Loss: 0.0519707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_C_S\n",
      "tensor(3592.5543, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.247797966003418\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.5696861 Vali Loss: 0.0951941 Test Loss: 0.1064660\n",
      "Validation loss decreased (inf --> 0.095194).  Saving model ...\n",
      "Epoch: 2 cost time: 8.384362936019897\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.2618592 Vali Loss: 0.0806610 Test Loss: 0.0415062\n",
      "Validation loss decreased (0.095194 --> 0.080661).  Saving model ...\n",
      "Epoch: 3 cost time: 8.27216911315918\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2324441 Vali Loss: 0.0766250 Test Loss: 0.0731087\n",
      "Validation loss decreased (0.080661 --> 0.076625).  Saving model ...\n",
      "Epoch: 4 cost time: 8.132933855056763\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2143444 Vali Loss: 0.0754106 Test Loss: 0.0895549\n",
      "Validation loss decreased (0.076625 --> 0.075411).  Saving model ...\n",
      "Epoch: 5 cost time: 8.376290082931519\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2053985 Vali Loss: 0.0718840 Test Loss: 0.0829402\n",
      "Validation loss decreased (0.075411 --> 0.071884).  Saving model ...\n",
      "Epoch: 6 cost time: 8.691529989242554\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.1920903 Vali Loss: 0.0891812 Test Loss: 0.0865740\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 7 cost time: 8.178791046142578\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.1780346 Vali Loss: 0.0779608 Test Loss: 0.0990700\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 8 cost time: 8.06397008895874\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.1565959 Vali Loss: 0.0803297 Test Loss: 0.0729765\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_D_S\n",
      "tensor(3415.4307, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.524415016174316\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.5749919 Vali Loss: 0.1069888 Test Loss: 0.0366711\n",
      "Validation loss decreased (inf --> 0.106989).  Saving model ...\n",
      "Epoch: 2 cost time: 8.50217318534851\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3847475 Vali Loss: 0.0820234 Test Loss: 0.0446826\n",
      "Validation loss decreased (0.106989 --> 0.082023).  Saving model ...\n",
      "Epoch: 3 cost time: 8.52285099029541\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.3569186 Vali Loss: 0.0723389 Test Loss: 0.0478382\n",
      "Validation loss decreased (0.082023 --> 0.072339).  Saving model ...\n",
      "Epoch: 4 cost time: 8.71104097366333\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.3375907 Vali Loss: 0.0696731 Test Loss: 0.0769176\n",
      "Validation loss decreased (0.072339 --> 0.069673).  Saving model ...\n",
      "Epoch: 5 cost time: 8.641710042953491\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3075458 Vali Loss: 0.0741538 Test Loss: 0.0361191\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 8.800561904907227\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2644668 Vali Loss: 0.0811597 Test Loss: 0.0341840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 8.616816759109497\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.2232829 Vali Loss: 0.0807321 Test Loss: 0.0261476\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_A_S\n",
      "tensor(163.3993, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 9.21286392211914\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8408034 Vali Loss: 1.2823248 Test Loss: 0.2335204\n",
      "Validation loss decreased (inf --> 1.282325).  Saving model ...\n",
      "Epoch: 2 cost time: 9.163778066635132\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.6332348 Vali Loss: 1.2490829 Test Loss: 0.0686336\n",
      "Validation loss decreased (1.282325 --> 1.249083).  Saving model ...\n",
      "Epoch: 3 cost time: 9.170829057693481\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.5763354 Vali Loss: 1.1395768 Test Loss: 0.2535089\n",
      "Validation loss decreased (1.249083 --> 1.139577).  Saving model ...\n",
      "Epoch: 4 cost time: 9.296953916549683\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.5326287 Vali Loss: 1.0795628 Test Loss: 0.0805276\n",
      "Validation loss decreased (1.139577 --> 1.079563).  Saving model ...\n",
      "Epoch: 5 cost time: 9.48574185371399\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.5084116 Vali Loss: 0.9899356 Test Loss: 0.0683122\n",
      "Validation loss decreased (1.079563 --> 0.989936).  Saving model ...\n",
      "Epoch: 6 cost time: 9.255482196807861\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4891694 Vali Loss: 1.0360748 Test Loss: 0.0891818\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 7 cost time: 9.390678882598877\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.4746726 Vali Loss: 1.1069875 Test Loss: 0.1405210\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 8 cost time: 9.409268856048584\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.4488982 Vali Loss: 1.0351175 Test Loss: 0.0864719\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_A_J\n",
      "tensor(365.8964, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.84154486656189\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.4673675 Vali Loss: 4.8641119 Test Loss: 0.3014581\n",
      "Validation loss decreased (inf --> 4.864112).  Saving model ...\n",
      "Epoch: 2 cost time: 8.816878080368042\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.3339603 Vali Loss: 5.8657832 Test Loss: 0.1660088\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.882529973983765\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2848835 Vali Loss: 8.1808681 Test Loss: 0.3594109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 4 cost time: 8.955053806304932\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2466334 Vali Loss: 8.8116293 Test Loss: 0.3838432\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for RD_D_S\n",
      "tensor(182.9500, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.810703992843628\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7682909 Vali Loss: 1.1111203 Test Loss: 0.1458058\n",
      "Validation loss decreased (inf --> 1.111120).  Saving model ...\n",
      "Epoch: 2 cost time: 8.85078501701355\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.5439251 Vali Loss: 0.9944501 Test Loss: 0.0454401\n",
      "Validation loss decreased (1.111120 --> 0.994450).  Saving model ...\n",
      "Epoch: 3 cost time: 9.097239017486572\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4891623 Vali Loss: 0.9426282 Test Loss: 0.0446285\n",
      "Validation loss decreased (0.994450 --> 0.942628).  Saving model ...\n",
      "Epoch: 4 cost time: 8.71825885772705\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4575494 Vali Loss: 0.9323187 Test Loss: 0.0449009\n",
      "Validation loss decreased (0.942628 --> 0.932319).  Saving model ...\n",
      "Epoch: 5 cost time: 8.730349063873291\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.4459817 Vali Loss: 0.9560975 Test Loss: 0.0418278\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 6 cost time: 8.768192768096924\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4340148 Vali Loss: 0.9420498 Test Loss: 0.0511411\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 7 cost time: 8.922355890274048\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.4138828 Vali Loss: 0.9671696 Test Loss: 0.0664499\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for TG_B_S\n",
      "tensor(3359.9743, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.662091970443726\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.5456392 Vali Loss: 0.0940116 Test Loss: 0.1026438\n",
      "Validation loss decreased (inf --> 0.094012).  Saving model ...\n",
      "Epoch: 2 cost time: 10.325173139572144\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.2884894 Vali Loss: 0.0801561 Test Loss: 0.1439871\n",
      "Validation loss decreased (0.094012 --> 0.080156).  Saving model ...\n",
      "Epoch: 3 cost time: 7.997663974761963\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.2501513 Vali Loss: 0.0801073 Test Loss: 0.0634428\n",
      "Validation loss decreased (0.080156 --> 0.080107).  Saving model ...\n",
      "Epoch: 4 cost time: 8.014084100723267\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.2290857 Vali Loss: 0.0829381 Test Loss: 0.0858262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 7.92883825302124\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.2191707 Vali Loss: 0.0808891 Test Loss: 0.1121482\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.112648963928223\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.2111001 Vali Loss: 0.0800162 Test Loss: 0.0753024\n",
      "Validation loss decreased (0.080107 --> 0.080016).  Saving model ...\n",
      "Epoch: 7 cost time: 8.155709981918335\n",
      "Epoch: 7, Steps: 81 | Train Loss: 0.1981240 Vali Loss: 0.0846119 Test Loss: 0.0866952\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 8 cost time: 8.432135820388794\n",
      "Epoch: 8, Steps: 81 | Train Loss: 0.1817203 Vali Loss: 0.0866541 Test Loss: 0.0899370\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 9 cost time: 8.261168003082275\n",
      "Epoch: 9, Steps: 81 | Train Loss: 0.1707046 Vali Loss: 0.0949144 Test Loss: 0.0653825\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CB_D_J\n",
      "tensor(102.5314, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.582727909088135\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8679882 Vali Loss: 0.7995874 Test Loss: 1.0543482\n",
      "Validation loss decreased (inf --> 0.799587).  Saving model ...\n",
      "Epoch: 2 cost time: 8.662631034851074\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.6898297 Vali Loss: 0.8080367 Test Loss: 0.8545677\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 3 cost time: 8.792861938476562\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.6401584 Vali Loss: 0.7368080 Test Loss: 0.5323047\n",
      "Validation loss decreased (0.799587 --> 0.736808).  Saving model ...\n",
      "Epoch: 4 cost time: 8.638728141784668\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.5527686 Vali Loss: 0.7910965 Test Loss: 0.5344594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.78562307357788\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.5020227 Vali Loss: 0.7935960 Test Loss: 0.8761424\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.61869215965271\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.4304038 Vali Loss: 0.7943006 Test Loss: 1.0170956\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for CB_A_J\n",
      "tensor(147.6114, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.179732084274292\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.8498273 Vali Loss: 4.5530248 Test Loss: 0.9172252\n",
      "Validation loss decreased (inf --> 4.553025).  Saving model ...\n",
      "Epoch: 2 cost time: 8.339571952819824\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.6774242 Vali Loss: 4.0329018 Test Loss: 1.3090626\n",
      "Validation loss decreased (4.553025 --> 4.032902).  Saving model ...\n",
      "Epoch: 3 cost time: 8.588964939117432\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.6162527 Vali Loss: 4.2607989 Test Loss: 1.0915289\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 4 cost time: 8.580404996871948\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.5706070 Vali Loss: 4.4588037 Test Loss: 1.2438499\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 5 cost time: 8.755248069763184\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.5213385 Vali Loss: 4.5111880 Test Loss: 1.7717621\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n",
      "--training for BC_B_J\n",
      "tensor(848.9786, dtype=torch.float64)\n",
      "Epoch: 1 cost time: 8.287369012832642\n",
      "Epoch: 1, Steps: 81 | Train Loss: 0.7038792 Vali Loss: 0.4884546 Test Loss: 0.1824882\n",
      "Validation loss decreased (inf --> 0.488455).  Saving model ...\n",
      "Epoch: 2 cost time: 8.514155864715576\n",
      "Epoch: 2, Steps: 81 | Train Loss: 0.4972607 Vali Loss: 0.3529867 Test Loss: 0.1782688\n",
      "Validation loss decreased (0.488455 --> 0.352987).  Saving model ...\n",
      "Epoch: 3 cost time: 8.31891918182373\n",
      "Epoch: 3, Steps: 81 | Train Loss: 0.4434852 Vali Loss: 0.3472385 Test Loss: 0.1137453\n",
      "Validation loss decreased (0.352987 --> 0.347239).  Saving model ...\n",
      "Epoch: 4 cost time: 8.658767700195312\n",
      "Epoch: 4, Steps: 81 | Train Loss: 0.4145964 Vali Loss: 0.3856772 Test Loss: 0.2492731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5 cost time: 8.610032320022583\n",
      "Epoch: 5, Steps: 81 | Train Loss: 0.3797848 Vali Loss: 0.3901823 Test Loss: 0.3088829\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6 cost time: 8.360678911209106\n",
      "Epoch: 6, Steps: 81 | Train Loss: 0.3596978 Vali Loss: 0.3967420 Test Loss: 0.3749160\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "torch.Size([1, 28, 1])\n",
      "A\n",
      "test shape: (1, 1, 28, 1) (1, 1, 28, 1)\n",
      "test shape: (1, 28, 1) (1, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset_preds = {}\n",
    "loss_code = {}\n",
    "\n",
    "for dataset_code in unique_code:\n",
    "    print(f'--training for {dataset_code}')\n",
    "\n",
    "    # 데이터셋 객체 생성\n",
    "    dataset_train = Dataset_jeju(flag='train', size=[64, 28, 28], features='S', scale=True, timeenc=0, freq='d',code = dataset_code)\n",
    "    dataset_val = Dataset_jeju(flag='val', size=[64, 28, 28], features='S', scale=True, timeenc=0, freq='d',code = dataset_code)\n",
    "    dataset_test = Dataset_jeju(flag='test', size=[64, 28, 28], features='S', scale=True, timeenc=0, freq='d',code = dataset_code)\n",
    "\n",
    "    # 데이터로더 생성\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True, drop_last = True)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=16, shuffle=True, drop_last = True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, drop_last = False)\n",
    "\n",
    "\n",
    "\n",
    "    ###########\n",
    "    model = Model(configs)\n",
    "    epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    ################\n",
    "\n",
    "\n",
    "    train_loader = dataloader_train\n",
    "    vali_loader = dataloader_val\n",
    "    test_loader = dataloader_test\n",
    "\n",
    "    _, _, _, _, train_mean, train_std = next(iter(dataloader_train))\n",
    "    print(train_mean.view(-1)[0])\n",
    "\n",
    "\n",
    "\n",
    "    # set path of checkpoint for saving and loading model\n",
    "    path = 'Savemodel'\n",
    "    time_now = time.time()\n",
    "\n",
    "    train_steps = len(train_loader)\n",
    "\n",
    "    # EarlyStopping is typically a custom class or function that monitors the performance \n",
    "    # of a model during training, usually by tracking a certain metric (commonly validation \n",
    "    # loss or accuracy).It's a common technique used in deep learning to prevent overfitting \n",
    "    # during the training\n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "    #Optimizer and Loss Function Selection\n",
    "    model_optim = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        #begin training in this epoch\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark,_,_) in enumerate(train_loader):\n",
    "            iter_count += 1\n",
    "            model_optim.zero_grad()\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            batch_x = batch_x.float().to(device)  #input features\n",
    "            batch_y = batch_y.float().to(device)  #target features\n",
    "\n",
    "            # _mark holds information about time-related features. Specifically, it is a \n",
    "            # tensor that encodes temporal information and is associated with the \n",
    "            # input data batch_x.\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "            \n",
    "            outputs = model(batch_x, batch_x_mark)\n",
    "            f_dim = 0 \n",
    "            # f_dim = -1 if args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            # When train rounds attain some 100-multiple, print speed, left time, loss. etc feedback\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                speed = (time.time() - time_now) / iter_count\n",
    "                left_time = speed * ((epochs - epoch) * train_steps - i)\n",
    "                print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                iter_count = 0\n",
    "                time_now = time.time()\n",
    "\n",
    "            # #BP\n",
    "            # if args.use_amp:\n",
    "            #     scaler.scale(loss).backward()\n",
    "            #     scaler.step(model_optim)\n",
    "            #     scaler.update()\n",
    "            # else:\n",
    "            #     loss.backward()\n",
    "            #     model_optim.step()\n",
    "            loss.backward()\n",
    "            model_optim.step()\n",
    "\n",
    "        \n",
    "        #This epoch comes to end, print information\n",
    "        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "        train_loss = np.average(train_loss)\n",
    "\n",
    "        #run test and validation on current model\n",
    "        vali_loss = vali(model, vali_loader, criterion)\n",
    "        test_loss = vali(model, test_loader, criterion)\n",
    "\n",
    "        #print train, test, vali loss information\n",
    "        print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "            epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "        \n",
    "        #Decide whether to trigger Early Stopping. if early_stop is true, it means that \n",
    "        #this epoch's training is now at a flat slope, so stop further training for this epoch.\n",
    "        early_stopping(vali_loss, model, path)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            loss_code[dataset_code] = [train_loss, vali_loss, test_loss]\n",
    "            break\n",
    "\n",
    "        # #adjust learning keys\n",
    "        # adjust_learning_rate(model_optim, epoch + 1, args)\n",
    "\n",
    "    best_model_path = path + '/' + 'checkpoint.pth'\n",
    "\n",
    "    # loading the trained model's state dictionary from a saved checkpoint file \n",
    "    # located at best_model_path.\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    \n",
    "    preds = []\n",
    "    trues = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark,_,_) in enumerate(test_loader):\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "            \n",
    "            outputs = model(batch_x, batch_x_mark)\n",
    "            print(outputs.shape)\n",
    "            print('A')\n",
    "\n",
    "            f_dim = 0\n",
    "            outputs = outputs[:,-pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:,-pred_len:, f_dim:].to(device)\n",
    "        \n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            #inverse the data if scaled\n",
    "            \n",
    "            outputs = outputs * train_std[0].item() + train_mean[0].item()\n",
    "            batch_y = batch_y * train_std[0].item() + train_mean[0].item()\n",
    "    \n",
    "            pred = outputs#.view(-1).numpy()\n",
    "            true = batch_y\n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "  \n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)  # shape[batch_num, batch_size, pred_len, features]\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "    print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "    dataset_preds[dataset_code] = preds[-1:,:,:]\n",
    "        \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2717.1768 ],\n",
       "        [ 890.12463],\n",
       "        [2944.1694 ],\n",
       "        [3495.7256 ],\n",
       "        [3244.4382 ],\n",
       "        [3306.116  ],\n",
       "        [3811.4146 ],\n",
       "        [3387.369  ],\n",
       "        [ 760.145  ],\n",
       "        [3743.2026 ],\n",
       "        [3337.2354 ],\n",
       "        [3498.6956 ],\n",
       "        [3821.1152 ],\n",
       "        [4044.704  ],\n",
       "        [3407.897  ],\n",
       "        [1402.966  ],\n",
       "        [3953.2822 ],\n",
       "        [3621.0166 ],\n",
       "        [3794.6113 ],\n",
       "        [3982.6401 ],\n",
       "        [3868.79   ],\n",
       "        [3763.2544 ],\n",
       "        [1675.2627 ],\n",
       "        [3892.1572 ],\n",
       "        [3324.809  ],\n",
       "        [3622.9678 ],\n",
       "        [3597.1978 ],\n",
       "        [3640.6309 ]]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_preds['TG_A_J']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = []\n",
    "date = 20230304\n",
    "for i in range(28):\n",
    "    date_col.append(date + i)\n",
    "# print(date_col)\n",
    "\n",
    "\n",
    "\n",
    "result = []\n",
    "for i in range(len(unique_code)):\n",
    "    pred_adj = np.round(dataset_preds[unique_code[i]],1)\n",
    "\n",
    "    for j in range(28):\n",
    "        code = unique_code[i]\n",
    "        final = pred_adj.flatten()[j]\n",
    "        if date_col[j] in [20230305, 20230312, 20230319, 20230326]:\n",
    "            final = 0\n",
    "        else:\n",
    "            final = final\n",
    "\n",
    "        code_time = f\"{unique_code[i]}_{date_col[j]}\"\n",
    "        result.append([code_time, final])\n",
    "    \n",
    "    \n",
    "result_df = pd.DataFrame(result, columns = ['ID', 'pred'])\n",
    "submission = pd.read_csv(\"~/Developer/private/Dacon/jeju/data/sample_submission.csv\")\n",
    "\n",
    "\n",
    "# 'submission' 데이터프레임과 'result_df' 데이터프레임을 'ID'를 기준으로 병합\n",
    "final_submission = submission.merge(result_df, on='ID', how='left')\n",
    "\n",
    "# 'pred' 값을 'answer' 열에 복사\n",
    "final_submission['answer'] = final_submission['pred']\n",
    "\n",
    "# 'pred' 열 삭제\n",
    "final_submission.drop('pred', axis=1, inplace=True)\n",
    "\n",
    "# 60보자 작으면 삭제\n",
    "final_submission['answer'] = final_submission['answer'].apply(lambda x: 0 if x < 60 else x)\n",
    "\n",
    "\n",
    "# 업데이트된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "final_submission.to_csv(f'~/Developer/private/Dacon/jeju/csv/TimesNet_validmake_early3_lr0.001.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CR_D_S, CB_A_S, BC_B_S, BC_C_S, CR_E_S, RD_C_S\n",
    "\n",
    "submission = pd.read_csv('~/Developer/private/Dacon/jeju/csv/TimesNet_validmake_early3_lr0.001.csv')\n",
    "submission.loc[submission['ID'].str.contains('CR_D_S'), 'answer'] = 0\n",
    "submission.loc[submission['ID'].str.contains('CB_A_S'), 'answer'] = 0\n",
    "submission.loc[submission['ID'].str.contains('BC_B_S'), 'answer'] = 0\n",
    "submission.loc[submission['ID'].str.contains('BC_C_S'), 'answer'] = 0\n",
    "submission.loc[submission['ID'].str.contains('CR_E_S'), 'answer'] = 0\n",
    "submission.loc[submission['ID'].str.contains('RD_C_S'), 'answer'] = 0\n",
    "\n",
    "submission.to_csv('~/Developer/private/Dacon/jeju/csv/TimesNet_validmake_early3_lr0.001_rm0.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
